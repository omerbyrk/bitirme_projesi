{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c4ade9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\software\\Desktop\\maskrcnn\\Mask_RCNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import skimage.draw\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath('./')\n",
    "print (ROOT_DIR)\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR) \n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "from mrcnn.model import log\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'samples/coco/'))\n",
    "import coco\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718e8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANNOTATIONS_DIR = 'brain-tumor/data/new/annotations/' # directory with annotations for train/val sets\n",
    "DATASET_DIR = os.path.join(ROOT_DIR, 'data') # directory with image data\n",
    "MODEL_DIR = 'model_default_logs' \n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f5532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7317d0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.85\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           text_detector\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class TextDetectionConfig(Config):\n",
    "    \"\"\"Configuration for training on the text detection dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = 'text_detector'\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1  # background + text\n",
    "    DETECTION_MIN_CONFIDENCE = 0.85    \n",
    "    STEPS_PER_EPOCH = 100\n",
    "    LEARNING_RATE = 0.001\n",
    "    \n",
    "config = TextDetectionConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3df007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextScanDataset(utils.Dataset):\n",
    "    def load_text_scan(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the FarmCow dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"text\", 1, \"text\")\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"val\", \"test\", \"train\"]\n",
    "        \n",
    "        annotations = []\n",
    "        path_to_json_dir = os.path.join(DATASET_DIR, subset + '/ocr_results/')\n",
    "        for file_name in [file for file in os.listdir(path_to_json_dir) if file.endswith('.json')]:\n",
    "          with open(path_to_json_dir + file_name) as json_file:\n",
    "            annotation = json.load(json_file)\n",
    "            interested_area = list(annotation.values())[1][0]\n",
    "            interested_area[\"image_path\"] = os.path.join(DATASET_DIR, subset + '/documents/', file_name.replace(\"json\", \"png\"))\n",
    "            interested_area[\"image_file_name\"] = file_name\n",
    "            annotations.append(interested_area)      \n",
    "\n",
    "        # The VIA tool saves images in the JSON even if they don't have any\n",
    "        # annotations. Skip unannotated images.\n",
    "        annotations = [a for a in annotations if a['lines']]\n",
    "        \n",
    "        for a in annotations:\n",
    "            width = a[\"width\"]\n",
    "            height = a[\"height\"]\n",
    "            image_path= a[\"image_path\"]\n",
    "            image_file_name = a[\"image_file_name\"]\n",
    "            polygons = []\n",
    "\n",
    "\n",
    "            for line in a[\"lines\"]:\n",
    "                polygons.append(line['boundingBox'])\n",
    "                for word in line[\"words\"]:\n",
    "                     polygons.append(word['boundingBox'])\n",
    "\n",
    "\n",
    "            self.add_image(\n",
    "                    \"text\",\n",
    "                    image_id=image_file_name,  # use file name as a unique image id\n",
    "                    path=image_path,\n",
    "                    width=width, \n",
    "                    height=height,\n",
    "                    polygons=polygons\n",
    "                )\n",
    "        \n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a farm_cow dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"text\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon( p[1::2],  p[0::2])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "#         # Return mask, and array of class IDs of each instance. Since we have\n",
    "#         # one class ID only, we return an array of 1s\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"text\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a68fd0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:442: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:58: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3543: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3386: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1768: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\software\\Desktop\\maskrcnn\\Mask_RCNN\\mrcnn\\model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\software\\Desktop\\maskrcnn\\Mask_RCNN\\mrcnn\\utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\software\\Desktop\\maskrcnn\\Mask_RCNN\\mrcnn\\model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    }
   ],
   "source": [
    "model = modellib.MaskRCNN(\n",
    "    mode='training', \n",
    "    config=config, \n",
    "    model_dir=MODEL_DIR\n",
    ")\n",
    "\n",
    "model.load_weights(\n",
    "    COCO_MODEL_PATH, \n",
    "    by_name=True, \n",
    "    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425d6f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: model_default_logs\\text_detector20220511T1341\\mask_rcnn_text_detector_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:625: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\callbacks.py:705: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\software\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\callbacks.py:708: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 1411s - loss: 3.7165 - rpn_class_loss: 0.5415 - rpn_bbox_loss: 1.6858 - mrcnn_class_loss: 0.4329 - mrcnn_bbox_loss: 0.6414 - mrcnn_mask_loss: 0.4148 - val_loss: 2.9419 - val_rpn_class_loss: 0.2138 - val_rpn_bbox_loss: 1.4331 - val_mrcnn_class_loss: 0.4330 - val_mrcnn_bbox_loss: 0.4904 - val_mrcnn_mask_loss: 0.3716\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 857s - loss: 2.8566 - rpn_class_loss: 0.1934 - rpn_bbox_loss: 1.3800 - mrcnn_class_loss: 0.4723 - mrcnn_bbox_loss: 0.4459 - mrcnn_mask_loss: 0.3651 - val_loss: 2.9295 - val_rpn_class_loss: 0.2045 - val_rpn_bbox_loss: 1.4360 - val_mrcnn_class_loss: 0.4479 - val_mrcnn_bbox_loss: 0.4478 - val_mrcnn_mask_loss: 0.3933\n",
      "Epoch 3/10\n",
      " 99/100 [============================>.] - ETA: 3s - loss: 2.7050 - rpn_class_loss: 0.1635 - rpn_bbox_loss: 1.3155 - mrcnn_class_loss: 0.4709 - mrcnn_bbox_loss: 0.4065 - mrcnn_mask_loss: 0.3486"
     ]
    }
   ],
   "source": [
    "dataset_train = TextScanDataset()\n",
    "dataset_train.load_text_scan(DATASET_DIR, 'train')\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = TextScanDataset()\n",
    "dataset_val.load_text_scan(DATASET_DIR, 'val')\n",
    "dataset_val.prepare()\n",
    "\n",
    "dataset_test = TextScanDataset()\n",
    "dataset_test.load_text_scan(DATASET_DIR, 'test')\n",
    "dataset_test.prepare()\n",
    "\n",
    "print(\"Training network heads\")\n",
    "model.train(\n",
    "    dataset_train, dataset_val,\n",
    "    learning_rate=config.LEARNING_RATE,\n",
    "    epochs=10,\n",
    "    layers='heads',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981693dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(\n",
    "    mode=\"inference\", \n",
    "    config=config,\n",
    "    model_dir=MODEL_DIR\n",
    ")\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34135c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=7):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4800b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot_differences(dataset, img_id):\n",
    "    original_image, image_meta, gt_class_id, gt_box, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset, config, \n",
    "                               img_id, use_mini_mask=False)\n",
    "\n",
    "    results = model.detect([original_image], verbose=1)\n",
    "    r = results[0]\n",
    "\n",
    "    visualize.display_differences(\n",
    "        original_image,\n",
    "        gt_box, gt_class_id, gt_mask,\n",
    "        r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
    "        class_names = ['text'], title=\"\", ax=get_ax(),\n",
    "        show_mask=True, show_box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(dataset, ind):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(dataset.load_image[ind])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Original Image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c929ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "ind = 50\n",
    "#display_image(dataset_val, ind)\n",
    "predict_and_plot_differences(dataset_val, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0cf16d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
